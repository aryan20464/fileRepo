apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-config
  namespace: uatcmm
data:
  config.alloy: |-
    # Alloy config: Scrape pod metrics in uatcmm namespace, forward to Prometheus.
    discovery.kubernetes "pods" {
      role = "pod"
      namespaces {
        own_namespace = false
        names = ["uatcmm"]  # Scrape pods in uatcmm namespace only.
      }
      selectors {
        role = "pod"
        # Optional: Add label filters, e.g., label = "app in (my-app)"
      }
    }

    prometheus.scrape "pods" {
      targets    = discovery.kubernetes.pods.targets
      forward_to = [prometheus.remote_write.prometheus.receiver]
    }

    prometheus.remote_write "prometheus" {
      endpoint {
        url = "http://prometheus.uatcmm.svc.cluster.local:9090/api/v1/write"  # Your Prometheus remote_write endpoint.
        # Add basic_auth or headers if Prometheus requires authentication.
      }
    }

    # Optional: Logging for Alloy itself.
    logging {
      level  = "info"
      format = "logfmt"
    }



apiVersion: v1
kind: Service
metadata:
  name: alloy
  namespace: uatcmm
  labels:
    app: alloy
spec:
  selector:
    app: alloy
  ports:
  - name: http
    port: 12345
    targetPort: 12345
    protocol: TCP
  type: ClusterIP






apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: alloy
  namespace: uatcmm
  labels:
    app: alloy
spec:
  selector:
    matchLabels:
      app: alloy
  template:
    metadata:
      labels:
        app: alloy
    spec:
      serviceAccountName: alloy
      hostNetwork: true  # Optional but recommended for node-local scraping (e.g., kubelet on 127.0.0.1) or logs; allows access to host ports/network.
      dnsPolicy: ClusterFirstWithHostNet  # Use if hostNetwork is true.
      tolerations:
      - operator: Exists  # Allows running on all nodes, including tainted ones (e.g., control-plane).
      containers:
      - name: alloy
        image: your-registry/grafana-alloy:1.11.0  # Replace with your actual Docker image.
        imagePullPolicy: IfNotPresent
        args:
        - run
        - /etc/alloy/config.alloy
        - --server.http.listen-addr=0.0.0.0:12345
        - --server.http.ui-path-prefix=/alloy
        ports:
        - name: http
          containerPort: 12345
          protocol: TCP
        volumeMounts:
        - name: config
          mountPath: /etc/alloy
        - name: var-log  # Add for logs collection (see notes below).
          mountPath: /var/log
          readOnly: true
        resources:
          limits:
            cpu: "500m"
            memory: "512Mi"
          requests:
            cpu: "100m"
            memory: "128Mi"
      volumes:
      - name: config
        configMap:
          name: alloy-config
      - name: var-log  # Host volume for pod logs (required for Loki logs collection).
        hostPath:
          path: /var/log






# Add to existing config.alloy
loki.source.file "pods" {
  targets    = ["/var/log/pods/*/*/*.log"]  # Tail pod logs.
  forward_to = [loki.write.loki.receiver]
}

loki.write "loki" {
  endpoint {
    url = "http://loki.uatcmm.svc.cluster.local:3100/loki/api/v1/push"  # Your Loki endpoint.
  }
}
